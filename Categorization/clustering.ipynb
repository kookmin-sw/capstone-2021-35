{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "clustering.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1-72IU7CJ5-mhuQn6m83tgPEZGMTIVN-0",
      "authorship_tag": "ABX9TyNywNTkaXCiem6/neiHGqc6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hayeong-lee/capstone-2021-35/blob/master/Categorization/clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_ZfqYOBYsG9"
      },
      "source": [
        "##데이터로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "sRHqlN4nYkOL",
        "outputId": "9cb7fccc-ee67-443a-b462-c30817077595"
      },
      "source": [
        "# car_inspect_record_info_table\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "data = pd.read_csv('/content/drive/MyDrive/refined_data.csv',names=['id','type','description'])\n",
        "data=data[['id','description']] \n",
        "data.dropna(axis=0)\n",
        "data.drop_duplicates(['description'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2453128</td>\n",
              "      <td>엔진오일교환</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>2571754</td>\n",
              "      <td>엔진오일교환</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>2489559</td>\n",
              "      <td>엔진오일교환 에어크리너 엔진오일 오일필터</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>2709081</td>\n",
              "      <td>엔진오일 교체</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>2671899</td>\n",
              "      <td>엔진오일 교환</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263255</th>\n",
              "      <td>2508279</td>\n",
              "      <td>타이어 교체  앞으로 이동</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263256</th>\n",
              "      <td>2453224</td>\n",
              "      <td>조수석 뒤 타이어 교환   서비스센터</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263269</th>\n",
              "      <td>2698055</td>\n",
              "      <td>타이어 교환 동광정비  x D   타이어사이드윌펑크로교체</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263290</th>\n",
              "      <td>2422830</td>\n",
              "      <td>펑크 교환 장애처리 견인 입고 건</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263387</th>\n",
              "      <td>2903328</td>\n",
              "      <td>타이어옆면 찍힘으로 타이얼1본교환</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68724 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             id                      description\n",
              "0       2453128                          엔진오일교환 \n",
              "100     2571754                           엔진오일교환\n",
              "127     2489559          엔진오일교환 에어크리너 엔진오일 오일필터 \n",
              "128     2709081                     엔진오일 교체     \n",
              "129     2671899                     엔진오일 교환     \n",
              "...         ...                              ...\n",
              "263255  2508279              타이어 교체  앞으로 이동     \n",
              "263256  2453224             조수석 뒤 타이어 교환   서비스센터\n",
              "263269  2698055  타이어 교환 동광정비  x D   타이어사이드윌펑크로교체\n",
              "263290  2422830              펑크 교환 장애처리 견인 입고 건 \n",
              "263387  2903328            타이어옆면 찍힘으로 타이얼1본교환   \n",
              "\n",
              "[68724 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWtSchWMYyH9"
      },
      "source": [
        "##문장토큰화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqvSkp6_Y0r4",
        "outputId": "352e17d8-c670-4fac-999d-085890fcd868"
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('treebank')\n",
        "import pandas as pd\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycPd7_AadaSN"
      },
      "source": [
        "##토큰화, 어근추출출,벡터화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZ66vSMNdWgJ",
        "outputId": "90df245c-5e2b-47b6-9466-4ab9768626af"
      },
      "source": [
        "# 텍스트 단어들의 어근 원형을 추출하기 위해 함수 생성\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "import string\n",
        "# string.puncutaion에 문자열의 모든 구두점이 들어있음\n",
        "# 이를 활용해서 Tokenize시킬 때 구두점들을 제외하기 위한 것\n",
        "# ord('문자열') => 문자열의 ASCII코드를 반환해줌!\n",
        "# dict(key, value)형태로 모든 구두점의 각 ASCII코드를 key값으로 넣어주자!\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
        "lemmar = WordNetLemmatizer()\n",
        "\n",
        "# 토큰화한 각 단어들의 원형들을 리스트로 담아서 반환\n",
        "def LemTokens(tokens):\n",
        "    return [lemmar.lemmatize(token) for token in tokens]\n",
        "# 텍스트를 Input으로 넣어서 토큰화시키고 토큰화된 단어들의 원형들을 리스트로 담아 반환\n",
        "def LemNormalize(text):\n",
        "    # .translate인자에 구두점 dict넣어주어서 구두점 삭제해준 상태로 토큰화시키기!\n",
        "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n",
        "\n",
        "# Tf-idf 벡터화시키면서 cusotmized해준 토큰화+어근추출 방식 tokenizer인자에 넣어주기\n",
        "# 벡터화시킬 Tf-idf 도구 옵션 추가해서 구축\n",
        "# 1,2gram적용, 빈도수 0.05이하, 0.85이상의 빈도수 단어들 제거\n",
        "tfidf_vect = TfidfVectorizer(tokenizer=LemNormalize,\n",
        "                            stop_words='english', ngram_range=(1,2),\n",
        "                            min_df=0.05, max_df=0.85)\n",
        "# fit_transform으로 위에서 구축한 도구로 텍스트 벡터화\n",
        "ftr_vect = tfidf_vect.fit_transform(data['description'].values.astype('U'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:385: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  'stop_words.' % sorted(inconsistent))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pf_RN3P2iSFu"
      },
      "source": [
        "##clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPsKU9J5iR8y"
      },
      "source": [
        "# K-means로 20개 군집으로 문서 군집화시키기\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "kmeans = KMeans(n_clusters=48, max_iter=10000, random_state=42)\n",
        "# 비지도 학습이니 feature로만 학습시키고 예측\n",
        "cluster_label = kmeans.fit_predict(ftr_vect)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec0IJK7Uj6-o"
      },
      "source": [
        "# 군집화한 레이블값들을 document_df 에 추가하기\n",
        "data['cluster_label'] = cluster_label\n",
        "print(data.sort_values(by=['cluster_label']))\n",
        "data.dropna(axis=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wbumMsCkekx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ada22b45-9c64-4b38-8d28-23a83e0d043e"
      },
      "source": [
        "# 문서의 feature(단어별) cluster_centers_확인해보자\n",
        "cluster_centers = kmeans.cluster_centers_\n",
        "print(cluster_centers.shape)\n",
        "print(cluster_centers)\n",
        "# shape의 행은 클러스터 레이블, 열은 벡터화 시킨 feature(단어들)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48, 8)\n",
            "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 1.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.01667430e-01\n",
            "  6.10229394e-01 6.82849443e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.78083660e-01\n",
            "  0.00000000e+00 0.00000000e+00 6.33898613e-01 6.74703857e-01]\n",
            " [5.77143098e-01 5.77179932e-01 5.77724632e-01 1.00270179e-05\n",
            "  0.00000000e+00 0.00000000e+00 5.81142370e-06 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 5.49808243e-01\n",
            "  8.35290905e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  1.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.52032864e-01 5.52062352e-01 5.52604053e-01 2.91711224e-01\n",
            "  1.37480644e-04 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 5.12627976e-01\n",
            "  0.00000000e+00 0.00000000e+00 8.58513713e-01 0.00000000e+00]\n",
            " [4.59656565e-01 4.59681118e-01 4.60132172e-01 2.42896733e-01\n",
            "  3.69018534e-01 4.12933403e-01 0.00000000e+00 0.00000000e+00]\n",
            " [5.13934501e-01 5.13961954e-01 5.14466270e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 4.54978558e-01 0.00000000e+00]\n",
            " [4.49211657e-01 4.49235652e-01 4.49676456e-01 2.37377321e-01\n",
            "  0.00000000e+00 0.00000000e+00 3.97989043e-01 4.23608345e-01]\n",
            " [0.00000000e+00 1.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.23661636e-01 5.23689608e-01 5.24203469e-01 0.00000000e+00\n",
            "  4.20402674e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [9.99620965e-01 0.00000000e+00 0.00000000e+00 4.33682631e-03\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
            "  6.71474083e-01 0.00000000e+00 7.41028040e-01 0.00000000e+00]\n",
            " [5.61819893e-01 5.61849904e-01 5.62401209e-01 9.10223660e-02\n",
            "  1.38284857e-01 1.54741379e-01 0.00000000e+00 0.00000000e+00]\n",
            " [5.58892675e-01 5.58922529e-01 5.59470962e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 2.49227890e-01 0.00000000e+00]\n",
            " [3.15178423e-01 3.15195259e-01 3.15504538e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 8.37717970e-01 0.00000000e+00]\n",
            " [3.17415245e-01 3.17432200e-01 3.17743675e-01 3.35464048e-01\n",
            "  5.09650540e-01 5.70301252e-01 0.00000000e+00 0.00000000e+00]\n",
            " [5.04694923e-01 5.04721882e-01 5.05217131e-01 2.66696393e-01\n",
            "  4.05175939e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [6.87296283e-01 0.00000000e+00 0.00000000e+00 7.26377188e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [4.91619562e-01 4.91645822e-01 4.92128241e-01 5.23262630e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.62541013e-01 5.62571062e-01 5.63123075e-01 0.00000000e+00\n",
            "  2.22779763e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.70427493e-01 5.70457963e-01 5.71017715e-01 1.51869279e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.54586936e-01\n",
            "  0.00000000e+00 0.00000000e+00 8.53685694e-01 4.54319522e-01]\n",
            " [5.34392652e-01 5.34421197e-01 5.34945589e-01 1.48825889e-01\n",
            "  0.00000000e+00 0.00000000e+00 2.36728519e-01 2.51967178e-01]\n",
            " [4.05771249e-01 4.05792924e-01 4.06191101e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 7.10551374e-01 0.00000000e+00]\n",
            " [8.84146267e-01 0.00000000e+00 0.00000000e+00 4.67210208e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.39285105e-01 5.39313912e-01 5.39843104e-01 1.44958970e-01\n",
            "  2.16472704e-01 2.42233931e-01 0.00000000e+00 0.00000000e+00]\n",
            " [7.07087896e-01 7.07125666e-01 0.00000000e+00 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.56146817e-01 5.56176524e-01 5.56722262e-01 1.46942582e-01\n",
            "  2.23241109e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [6.14920044e-01 6.14952891e-01 0.00000000e+00 0.00000000e+00\n",
            "  4.93666164e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 8.84156575e-01 0.00000000e+00 4.67190700e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.32724151e-01 6.69853508e-01 5.12423365e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 2.76052609e-01\n",
            "  8.38780561e-01 4.69299614e-01 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.04255422e-01\n",
            "  6.14161175e-01 0.00000000e+00 6.77778434e-01 0.00000000e+00]\n",
            " [7.77106995e-01 4.37071547e-01 4.37500416e-01 4.21686216e-02\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 7.96307865e-01\n",
            "  6.04891547e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [4.95903202e-01 4.95929691e-01 4.96416314e-01 2.62050576e-01\n",
            "  0.00000000e+00 0.00000000e+00 4.39356455e-01 0.00000000e+00]\n",
            " [3.36958818e-01 3.36976817e-01 3.37307470e-01 2.58398363e-01\n",
            "  0.00000000e+00 0.00000000e+00 5.97072296e-01 4.61121150e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 3.12616554e-01\n",
            "  9.49879408e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 6.32595119e-01\n",
            "  0.00000000e+00 0.00000000e+00 5.30307457e-01 5.64444343e-01]\n",
            " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.65889905e-01\n",
            "  0.00000000e+00 0.00000000e+00 7.81115388e-01 4.15698626e-01]\n",
            " [4.80587500e-01 0.00000000e+00 0.00000000e+00 8.74864667e-01\n",
            "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
            " [5.74847973e-01 5.74878679e-01 5.75442769e-01 8.60145002e-02\n",
            "  1.46233223e-03 1.63635636e-03 0.00000000e+00 0.00000000e+00]\n",
            " [5.73094415e-01 5.68140108e-01 5.68697586e-01 0.00000000e+00\n",
            "  0.00000000e+00 0.00000000e+00 1.55487022e-01 0.00000000e+00]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGJIapwcppIz"
      },
      "source": [
        "##클러스터별 핵심단어 추출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCW-jpHAprO6"
      },
      "source": [
        "def get_cluster_details(cluster_model, cluster_data, feature_names,\n",
        "                       cluster_num, top_n_features=10):\n",
        "    cluster_details = {}\n",
        "    # 각 클러스터 레이블별 feature들의 center값들 내림차순으로 정렬 후의 인덱스를 반환\n",
        "    center_feature_idx = cluster_model.cluster_centers_.argsort()[:,::-1]\n",
        "    \n",
        "    # 개별 클러스터 레이블별로 \n",
        "    for cluster_num in range(cluster_num):\n",
        "        # 개별 클러스터별 정보를 담을 empty dict할당\n",
        "        cluster_details[cluster_num] = {}\n",
        "        cluster_details[cluster_num]['cluster'] = cluster_num\n",
        "        \n",
        "        # 각 feature별 center값들 정렬한 인덱스 중 상위 10개만 추출\n",
        "        top_ftr_idx = center_feature_idx[cluster_num, :top_n_features]\n",
        "        top_ftr = [feature_names[idx] for idx in top_ftr_idx]\n",
        "        # top_ftr_idx를 활용해서 상위 10개 feature들의 center값들 반환\n",
        "        # 반환하게 되면 array이기 떄문에 리스트로바꾸기\n",
        "        top_ftr_val = cluster_model.cluster_centers_[cluster_num, top_ftr_idx].tolist()\n",
        "        \n",
        "        # cluster_details 딕셔너리에다가 개별 군집 정보 넣어주기\n",
        "        cluster_details[cluster_num]['top_features'] = top_ftr\n",
        "        cluster_details[cluster_num]['top_featrues_value'] = top_ftr_val\n",
        "        # 해당 cluster_num으로 분류된 파일명(문서들) 넣어주기\n",
        "        id = cluster_data[cluster_data['cluster_label']==cluster_num]['id']\n",
        "        # id가 df으로 반환되기 떄문에 값들만 출력해서 array->list로 변환\n",
        "        id = id.values.tolist()\n",
        "        cluster_details[cluster_num]['id'] = id\n",
        "    \n",
        "    return cluster_details\n",
        "\n",
        "def print_cluster_details(cluster_details):\n",
        "    for cluster_num, cluster_detail in cluster_details.items():\n",
        "        print(f\"#####Cluster Num: {cluster_num}\")\n",
        "        print()\n",
        "        print(\"상위 10개 feature단어들:\\n\", cluster_detail['top_features'])\n",
        "        print()\n",
        "        print(f\"Cluster {cluster_num}으로 분류된 문서들:\\n{cluster_detail['id'][:5]}\")\n",
        "        print('-'*20)\n",
        "\n",
        "feature_names = tfidf_vect.get_feature_names()\n",
        "cluster_details = get_cluster_details(cluster_model=kmeans,\n",
        "                                     cluster_data=data,\n",
        "                                     feature_names=feature_names,\n",
        "                                     cluster_num=48,\n",
        "                                     top_n_features=10)\n",
        "print_cluster_details(cluster_details)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4eyTNaVyxdh"
      },
      "source": [
        "##clutering 결과 바탕으로 같은 label의 문서들 간 유사도 측정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZVNageGzBbt"
      },
      "source": [
        "# 클러스터링된 문서들 중에서 특정 문서를 하나 선택한 후 비슷한 문서 추출\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "hotel_idx = data[data['cluster_label']==1].index\n",
        "print(\"label1 카테고리로 클러스터링된 문서들의 인덱스:\\n\",hotel_idx)\n",
        "print()\n",
        "# label1 카테고리로 클러스터링 된 문서들의 인덱스 중 하나 선택해 비교 기준으로 삼을 문서 선정\n",
        "comparison_doc = data.iloc[hotel_idx[0]]['description']\n",
        "print(\"##유사도 비교 기준 문서 이름:\",comparison_doc,'##')\n",
        "print()\n",
        "\n",
        "# 위에서 추출한 label1 카테고리로 클러스터링된 문서들의 인덱스 중 0번인덱스(비교기준문서)제외한\n",
        "# 다른 문서들과의 유사도 측정\n",
        "similarity = cosine_similarity(ftr_vect[hotel_idx[0]], ftr_vect[hotel_idx])\n",
        "print(similarity)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}