{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KoBERT_fine-tunning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPDbLpnTLFeKKS3EvJIvEg5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd4707c4d32b443d8964f5fa784e92d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b438a5562b14a1da046097690656771",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee8e008d6c8a400795e73ea6c879ed93",
              "IPY_MODEL_8d05a6e29c7b47acafec08947dc0d56f"
            ]
          }
        },
        "5b438a5562b14a1da046097690656771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee8e008d6c8a400795e73ea6c879ed93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e5709f041e8c4f47ba50b654cc6999f8",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 21,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c5ff603007f841f98c66f7ef09deea63"
          }
        },
        "8d05a6e29c7b47acafec08947dc0d56f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c3199d3e24541ea8b8ba7ebc9b585f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/21 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a6f8daefb8034ff88a4511c3d1924468"
          }
        },
        "e5709f041e8c4f47ba50b654cc6999f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c5ff603007f841f98c66f7ef09deea63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c3199d3e24541ea8b8ba7ebc9b585f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a6f8daefb8034ff88a4511c3d1924468": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "14fe2330494c4d09a3926c8b634d88d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_eac392bff51147ab91ade2ad6957eb65",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2c49f4d7d37a442187a579f5cf31bcae",
              "IPY_MODEL_deca24955d1242e7a49f6f963a43c99e"
            ]
          }
        },
        "eac392bff51147ab91ade2ad6957eb65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2c49f4d7d37a442187a579f5cf31bcae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_05d46418461b4939919cfa385a54600a",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_58c4eaf06c8b4f068e52b2c8caa4c631"
          }
        },
        "deca24955d1242e7a49f6f963a43c99e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9b3456f7262c48c794401224417eb52c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/1 [00:24&lt;00:00, 24.12s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83eeb8b77b2842b7912dad5c37d24b17"
          }
        },
        "05d46418461b4939919cfa385a54600a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "58c4eaf06c8b4f068e52b2c8caa4c631": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9b3456f7262c48c794401224417eb52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83eeb8b77b2842b7912dad5c37d24b17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "393a3e20435347eb8ccdda4b000b54f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_53f252976f8b47e18087c6ac439ba674",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ada04ec8fa014074a04bb174063fed35",
              "IPY_MODEL_d0515eb1f8584f4abcdd5cc3df0db27f"
            ]
          }
        },
        "53f252976f8b47e18087c6ac439ba674": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ada04ec8fa014074a04bb174063fed35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_197bb5160b1845b2a4d03ac38da17f0e",
            "_dom_classes": [],
            "description": " 17%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 6,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_416d30bdddec483185529ca1d849e8d5"
          }
        },
        "d0515eb1f8584f4abcdd5cc3df0db27f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8290e52474d140049a27efde1569e66e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1/6 [00:01&lt;00:05,  1.11s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_405b0d23c5594fd4be7ce9a599e59527"
          }
        },
        "197bb5160b1845b2a4d03ac38da17f0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "416d30bdddec483185529ca1d849e8d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8290e52474d140049a27efde1569e66e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "405b0d23c5594fd4be7ce9a599e59527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Johyeyoung/capstone-2021-35/blob/master/Transaction/KoBERT/fine_tunning.py\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcayCA0LcbJ2",
        "outputId": "5fa17fe7-2654-477b-f454-46cbc56cb02a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFQbYNf7dYvI",
        "outputId": "a5981207-646a-4314-d6a9-209fcd581b85"
      },
      "source": [
        "\n",
        "# 학습용 데이터셋 불러오기\n",
        "import pandas as pd\n",
        "dataset_train1 = pd.read_csv('/content/drive/MyDrive/Trigger_list_내비_타이어.csv', encoding='cp949')\n",
        "dataset_train1.head()\n",
        "\n",
        "\n",
        "# 데이터 전처리\n",
        "dataset_train1.drop(['type_num'], axis=1, inplace=True)\n",
        "dataset_train1.head()\n",
        "# positive 비율을 확인했다를 확인 1:1로 맞춰줘야 비율\n",
        "# 같은 내용의 카테고리 합치기\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'하이패스_카드분실', repl=r'하이패스_분실', regex=True)\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'트렁크_파손', repl=r'트렁크_고장', regex=True)\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'거치대_(분실|파손)', repl=r'내비게이션_파손', regex=True)\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'내비게이션_인터넷연결불가', repl=r'내비게이션_고장', regex=True)\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'타이어_파스/펑크\\(후우\\)', repl=r'타이어_파스/펑크', regex=True)\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'타이어_파스/펑크\\(후좌\\)', repl=r'타이어_파스/펑크', regex=True)\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'타이어_파스/펑크\\(전우\\)', repl=r'타이어_파스/펑크', regex=True)\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'타이어_파스/펑크\\(전좌\\)', repl=r'타이어_파스/펑크', regex=True)\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'블랙박스_탈거', repl=r'블랙박스_고장', regex=True)\n",
        "dataset_train1[\"type\"] = dataset_train1[\"type\"].str.replace(pat=r'타이어_파스/펑크\\(전우\\)', repl=r'타이어_파스/펑크', regex=True)\n",
        "\n",
        "\n",
        "dataset_train1['type'].unique()\n",
        "\n",
        "# 대표 증상 5개 추출\n",
        "data1 = dataset_train1[dataset_train1['type'] == '타이어_파스/펑크']\n",
        "data2 = dataset_train1[dataset_train1['type'] == '내비게이션_고장']\n",
        "data3 = dataset_train1[dataset_train1['type'] == '블랙박스_고장']\n",
        "data4 = dataset_train1[dataset_train1['type'] == '하이패스_분실']\n",
        "data5 = dataset_train1[dataset_train1['type'] == '주행_차량떨림']\n",
        "\n",
        "new_data = data1.append([data2, data3, data4, data5], sort=False)\n",
        "new_data = pd.DataFrame(new_data)\n",
        "new_data.head()\n",
        "\n",
        "# 질병명 라벨링\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(new_data['type'])\n",
        "new_data['type'] = encoder.transform(new_data['type'])\n",
        "new_data.head()\n",
        "\n",
        "# 라벨링된 type 매핑 ex) {0: '타이어_파스/펑크', 1: '내비게이션_고장', 2: '수족냉증', 3: '식중독', 4: '질염'}\n",
        "mapping = dict(zip(range(len(encoder.classes_)), encoder.classes_))\n",
        "mapping\n",
        "\n",
        "# Train / Test set 분리\n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(new_data, test_size=0.2, random_state=42)\n",
        "print(\"train shape is:\", len(train))\n",
        "print(\"test shape is:\", len(test))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train shape is: 1341\n",
            "test shape is: 336\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7Ko6gdmimNH",
        "outputId": "f77a1263-5111-450e-a8f8-122a675e08e8"
      },
      "source": [
        "# 이는 구글 코랩으로 돌린 버전입니다. 그리고 기본 코드는 SKT Brain의 KoBERT를 그대로 가져왔고, 학습 및 테스트 데이터셋만 따로 준비한 것입니다.\n",
        "# SKT Brain github 주소는 다음과 같습니다. https://github.com/SKTBrain/KoBERT\n",
        "\n",
        "!pip install mxnet\n",
        "!pip install gluonnlp pandas tqdm\n",
        "!pip install sentencepiece\n",
        "!pip install transformers==3 # 최신 버전으로 설치하면 \"Input: must be Tensor, not str\" 라는 에러 발생\n",
        "!pip install torch\n",
        "\n",
        "!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import gluonnlp as nlp\n",
        "import numpy as np\n",
        "from tqdm import tqdm, tqdm_notebook\n",
        "\n",
        "from kobert.utils import get_tokenizer\n",
        "from kobert.pytorch_kobert import get_pytorch_kobert_model\n",
        "\n",
        "from transformers import AdamW\n",
        "from transformers.optimization import get_cosine_schedule_with_warmup\n",
        "\n",
        "##GPU 사용 시\n",
        "device = torch.device(\"cuda:0\")\n",
        "bertmodel, vocab = get_pytorch_kobert_model()\n",
        "\n",
        "# 기본 Bert tokenizer 사용\n",
        "tokenizer = get_tokenizer()\n",
        "tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)\n",
        "\n",
        "\n",
        "class BERTDataset(Dataset):\n",
        "    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n",
        "                 pad, pair):\n",
        "        transform = nlp.data.BERTSentenceTransform(\n",
        "            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair) \n",
        "\n",
        "        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n",
        "        self.labels = [np.int32(i[label_idx]) for i in dataset]\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return (self.sentences[i] + (self.labels[i], ))\n",
        "\n",
        "    def __len__(self):\n",
        "        return (len(self.labels))\n",
        "\n",
        "\n",
        "        \n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mxnet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/07/66174e78c12a3048db9039aaa09553e35035ef3a008ba3e0ed8d2aa3c47b/mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9MB)\n",
            "\u001b[K     |████████████████████████████████| 46.9MB 62kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n",
            "Collecting gluonnlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/81/a238e47ccba0d7a61dcef4e0b4a7fd4473cb86bed3d84dd4fe28d45a0905/gluonnlp-0.10.0.tar.gz (344kB)\n",
            "\u001b[K     |████████████████████████████████| 348kB 12.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.22)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (20.9)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595694 sha256=3f273a70a173fb418148f76ada20aeccdb63632b560e171273010767ab0cf493\n",
            "  Stored in directory: /root/.cache/pip/wheels/37/65/52/63032864a0f31a08b9a88569f803b5bafac8abd207fd7f7534\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 11.2MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.95\n",
            "Collecting transformers==3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/35/1c3f6e62d81f5f0daff1384e6d5e6c5758682a8357ebc765ece2b9def62b/transformers-3.0.0-py3-none-any.whl (754kB)\n",
            "\u001b[K     |████████████████████████████████| 757kB 11.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n",
            "Collecting tokenizers==0.8.0-rc4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/82/0e82a95bd9db2b32569500cc1bb47aa7c4e0f57aa5e35cceba414096917b/tokenizers-0.8.0rc4-cp37-cp37m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 24.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.95)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/08/cd/342e584ee544d044fb573ae697404ce22ede086c9e87ce5960772084cad0/sacremoses-0.0.44.tar.gz (862kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.44-cp37-none-any.whl size=886084 sha256=007aab2568d083f918f6d4c7aed57269f68779bd124167841c6e32c3b12b9b8e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/fb/c0/13ab4d63d537658f448366744654323077c4d90069b6512f3c\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.44 tokenizers-0.8.0rc4 transformers-3.0.0\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n",
            "Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n",
            "  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-y8yia5zr\n",
            "  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-y8yia5zr\n",
            "Building wheels for collected packages: kobert\n",
            "  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kobert: filename=kobert-0.1.2-cp37-none-any.whl size=12708 sha256=3ec20f17300e9aad0301902abed3161780cc6fe60472b7aaf4245a4680cea18a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-mtjnm0bd/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n",
            "Successfully built kobert\n",
            "Installing collected packages: kobert\n",
            "Successfully installed kobert-0.1.2\n",
            "[██████████████████████████████████████████████████]\n",
            "[██████████████████████████████████████████████████]\n",
            "using cached model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcOt8w6Yi7QY",
        "outputId": "e9aed1ef-5cde-4748-d0f7-543a4ac65e86"
      },
      "source": [
        "train_list = []\n",
        "type_num = train['type'].values.tolist()\n",
        "question = train['문의 내용'].values.tolist()\n",
        "for i in range(len(type_num)):\n",
        "  train_list.append([question[i], type_num[i]])\n",
        "\n",
        "# 비율 확인\n",
        "for i in range(6):\n",
        "  print(type_num.count(i))\n",
        "\n",
        "test_list = []\n",
        "type_num = test['type'].values.tolist()\n",
        "question = test['문의 내용'].values.tolist()\n",
        "for i in range(len(type_num)):\n",
        "  test_list.append([question[i], type_num[i]])\n",
        "\n",
        "# 비율 확인\n",
        "for i in range(6):\n",
        "  print(type_num.count(i))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "862\n",
            "108\n",
            "80\n",
            "273\n",
            "18\n",
            "0\n",
            "228\n",
            "22\n",
            "17\n",
            "66\n",
            "3\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMt9UJvv5cWj",
        "outputId": "2a56e9aa-9c25-4bb6-e8bc-015532c76e5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for i in range(len(test_list)):\n",
        "  print(test_list[i])"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['차량 떨림 대차 요청', 2]\n",
            "['내비게이션 작동 불가 문의', 0]\n",
            "['TPMS 경고등', 3]\n",
            "['타이어 공기압 경고등 점등', 3]\n",
            "['초행길 한밤중에 고속도로에서 내비가 작동 불능', 0]\n",
            "['내비게이션 안돼서 인입', 0]\n",
            "['뒤에 초보운전 스티커 붙여놓으셨던데 누가 붙이신 건지 몰라도 맞는 건지 몰라서 문의 남깁니다', 2]\n",
            "['내비게이션 문제 발생으로 인입', 0]\n",
            "['주행 중 떨림으로 인한 현장 확인 필요', 2]\n",
            "['TCS 오작동 실행 준비 중', 0]\n",
            "['내비 인터넷 연결이 안 됨 티맵 실행 중에서 안 넘어감', 0]\n",
            "['너비가 잘못돼서 고속도로 나갔다가 들어왔다 번 정도 반복 점검 요청', 0]\n",
            "['내비게이션 터치 안됨', 0]\n",
            "['너비가 됐다 안됐다 함', 0]\n",
            "['대차 존 도착 후 인입', 0]\n",
            "['타이어 파손 육안 확인', 3]\n",
            "['조수석 앞 타이어 펑크 바닥에 주저앉아 있음', 3]\n",
            "['타이어 찢어짐 및 대체 가능한 타이어 없음으로 불가함 운전석 뒷바퀴', 3]\n",
            "['내비게이션 작동 안 되어 인입', 0]\n",
            "['내비 전원 불가 문의', 0]\n",
            "['T맵 실행 불가', 0]\n",
            "['내비게이션 화면 출력 불가 및 후방카메라 화면 안 나와 인입', 0]\n",
            "['차량 내비 화면 안 나와 문의', 0]\n",
            "['내비게이션 사용하다 갑자기 전원이 나오지 않고 작동 안 되어 인입', 0]\n",
            "['내비게이션 고장으로 인해 인입 계속 T맵 실행 중입니다라고 나온다고 함', 0]\n",
            "['네비 소리가 깨져서 들리고 인증 정보 확인하라고 나오면서 계속 재부팅됨', 0]\n",
            "['내비게이션 이용불가 기기가 작동하지 않음', 0]\n",
            "['내비게이션 안 켜진다 함', 0]\n",
            "['차량 흔들거림 및 기아 들어갈 때 심하게 느껴진다고 하심', 2]\n",
            "['내비게이션 재시작 해도 안된다 하심', 0]\n",
            "['내비게이션 목적지 설정 불가로 문의 서비스 지연', 0]\n",
            "['네비게이션이 중국어로 설정되어있음 한국어로 못 바꾸는지', 0]\n",
            "['타이어 못 박혀 가능한지 확인 필요', 3]\n",
            "['정지에서 출발할 때 떨림 발생', 2]\n",
            "['블랙박스 불량', 1]\n",
            "['타이어 펑크로 인입', 3]\n",
            "['하이패스 카드 없다는 멘트 확인', 4]\n",
            "['내비 네트워크 실행 안됨', 0]\n",
            "['내비게이션이 다른 곳을 가리키고 있어 인입', 0]\n",
            "['후방 우측 타이어 펑크 및 파스', 3]\n",
            "['블랙박스 고장', 1]\n",
            "['내비 화면 들어오지 않음 인입', 0]\n",
            "['타이어 펑크로 문의', 3]\n",
            "['타이어 파손 육안 확인', 3]\n",
            "['전원 가능', 0]\n",
            "['내비 안 되어 인입', 0]\n",
            "['내비게이션 문제', 0]\n",
            "['내비게이션 안됨', 0]\n",
            "['타이어 바람 빠짐으로 긴급출동 기사 이동했으나 현장에서 타이어 파스로 확인 공업사 요청 전우', 3]\n",
            "['내비게이션 실행 준비 중입니다가 계속 나오면서 너비가 안됨', 0]\n",
            "['내비게이션 사용 불가', 0]\n",
            "['앞 범퍼 부분 손상 및 타이어 파스 있음', 3]\n",
            "['와이파이 연결 불가 내비 오작동 인입', 0]\n",
            "['내비게이션 SD카드 오류', 0]\n",
            "['Tmap 실행 준비 중입니다라고 많 뜨고 내비 작동이 안 됨', 0]\n",
            "['서비스가 지연되고 있다고 뜨면서 내비 안됨', 0]\n",
            "['담배 냄새가 난다고 함 내비게이션 작동이 안 된다고 함', 0]\n",
            "['블루투스 연결 문의', 0]\n",
            "['내비게이션 화면 꺼짐', 0]\n",
            "['와이파이 연결 확인하라고 하면서 내비 작동이 안 되고 있음', 0]\n",
            "['차량 주행 떨림 긴급출동', 2]\n",
            "['내비 인터넷 연결이 안 되어 문의', 0]\n",
            "['쏘카 패스를 이용하고 있으면 바로 반납을 해도 크레디트가 적립 안되는지', 0]\n",
            "['타이어 펑크로 문의', 3]\n",
            "['사고 공업사 입고 중 블랙박스 작동 불가 확인', 1]\n",
            "['내비게이션이 라디오 화면으로 계속 바뀐다고 함', 0]\n",
            "['내비게이션 문제', 0]\n",
            "['내비게이션 또 작동 안 된다며 인입', 0]\n",
            "['내비게이션 정상작동하지 않음', 0]\n",
            "['운행 전 타이어 펑크', 3]\n",
            "['내비가 안된다며 고객 인입', 0]\n",
            "['내비게이션이 되지 않는다', 0]\n",
            "['내비게이션 T맵 연결 및 네트워크 연결 실패', 0]\n",
            "['내비게이션이 안된다고 불만 장골', 0]\n",
            "['메모리카드가 없다는 문구 뜸', 1]\n",
            "['내비게이션 소리 이 출력으로 인입', 0]\n",
            "['내비 지속 꺼짐으로 인입', 0]\n",
            "['반납하기 안됨 왜 안되냐 함', 0]\n",
            "['내비게이션과 차량의 속도가 싱크 안 맞고 카오디오가 연결이 됐다 안됐다 한다고 함', 0]\n",
            "['내비 화면 오작동 문의', 0]\n",
            "['내비게이션 티맵 작동 안 함 껐다 켜도 안됨', 0]\n",
            "['운행 전 타이어 쪽 소음 발생 경고 등 점등으로 앱 내 반납 시 시간 때문에 반납 불가하여 문의', 3]\n",
            "['내비게이션 연결 불가', 0]\n",
            "['모닝 전 좌 타이어 공기 아브로 실펑크 의심', 3]\n",
            "['타이어에 못이 박혀있어 인입 경고등도 따로 없다고 하심 따로 접촉도 없었다고 하심', 3]\n",
            "['고객이 언급한 대로 상세 장애 내용 작성', 0]\n",
            "['너비가 SD카드가 없다고 뜸', 0]\n",
            "['후좌 타이어 펑크', 3]\n",
            "['나오지 않음', 0]\n",
            "['내비는 작동 잘 되나 내비 안에 부가적인 서비스 버튼이 작동되지 않는다고 문의', 0]\n",
            "['내비게이션 정상 작동되지 안흥', 0]\n",
            "['타이어 파스 운행불가', 3]\n",
            "['내비게이션이 안된다며 항의 인입', 0]\n",
            "['블랙박스 좌측 루프 천장 쪽 외관 손상으로 인한 블랙박스 탈 거 떨어짐', 1]\n",
            "['타이어 펑크 키 아웃', 3]\n",
            "['타이어 쪽에 문제가 있는 거 같아 인입', 2]\n",
            "['내비게이션이 계속 지우는 중 화면만 뜨고 작동이 안 됨', 0]\n",
            "['내비게이션 및 후방카메라 둘 다 안 나옴 디스플레이 작동 자체가 안됨', 0]\n",
            "['서비스 지연 문구 발생', 0]\n",
            "['내비게이션 작동하지 않음', 0]\n",
            "['내비게이션 장애', 0]\n",
            "['타이어 파손 육안 확인', 3]\n",
            "['이전 상담 시 원격으로 재시작해주었지만 계속해서 내비게이션 화면 꺼진다고 함 대차 요청', 0]\n",
            "['주유카드 와 블랙박스 탈거로 문의', 1]\n",
            "['tcs t맵 실행 준비 중 지속 발생 재시작 버튼 없다 함', 0]\n",
            "['티맵 실행되지 않음', 0]\n",
            "['차량 이용하려고 했는데 보니까 타이어가 터져있음', 3]\n",
            "['내비게이션 화면이 켜졌다 꺼졌다 반복돼서 인입', 0]\n",
            "['전 좌우 타이어 교체 시급 가온 오토 화성점 입고', 3]\n",
            "['전 좌 타이어 펑크', 3]\n",
            "['전우 타이어 파스 후 좌 타이어 못 박힘', 3]\n",
            "['너비가 sd카드를 삽입하라는 문구 나오고 안됨', 0]\n",
            "['전우 타이어 펑크 조치 필요 공기압 보충 불가', 3]\n",
            "['내비게이션 오작동 불만', 0]\n",
            "['반납 후 고객 인입하여 해당 차량 내비게이션 음량이 불량하여 소리 끄고 운행했다 호소', 0]\n",
            "['내비게이션 이용불가 경로탐색 누르면 초기화면으로 이동', 0]\n",
            "['내비 장애 제보 이용 중 지속적으로 발생되는 문제라 하시며 유선 상담 시 제보하였으나 개선되지 않는다며 불만 정확한 장애 내용 확인 불가', 0]\n",
            "['호 더 뉴아반떼 앞바퀴가 펑크 나서 바람 빠짐', 3]\n",
            "['내비게이션 사용하려 하나 네트워크 연결 안 된다 함 어떻게 하는지', 0]\n",
            "['내비게이션 아까 초기화해준다고 했으나 초기화가 안됐다며 인입 다시 초기화 해달라고 하심', 0]\n",
            "['모바일 데이터 또는 WI FI 연결 상태를 확인해주세요', 0]\n",
            "['탑승 전 타이어 문제 확인', 3]\n",
            "['네트워크 연결 불가', 0]\n",
            "['차량 블랙박스가 후면은 촬영이 안 되는지', 1]\n",
            "['내비게이션 틀고 싶음 네트워크 연결되어 있지 않다 함', 0]\n",
            "['네비게이션 블루투스 연결 불가', 0]\n",
            "['내비 오작동으로 인입', 0]\n",
            "['반납하려고 하는 도중 보조석 앞 타이어 찢어짐 확인인 입', 3]\n",
            "['내비게이션 실행 오류', 0]\n",
            "['차량 제동등 점검으로 공업사 갈려고 했으나', 0]\n",
            "['네비게이션 블루투스 연결 불가', 0]\n",
            "['내비게이션 소리가 안 나온다고 하심', 0]\n",
            "['차량 내비게이션 문제로 더 이상 이용을 할 수 없어 반납함', 0]\n",
            "['내비게이션 및 와이파이 연결 불가 로인입', 0]\n",
            "['확인 내용 대차 사유 블랙박스 메모리카드 확인 필요', 1]\n",
            "['내비게이션이 안되고 후방카메라가 안된다고 하심', 0]\n",
            "['블랙박스 메모리 확인하라는 멘트 나온다고 함', 1]\n",
            "['T맵 실행 중 화면유지', 0]\n",
            "['내비게이션 고장으로 인해 인입 사용자 인증정보가 맞지 않아 계속 로그아웃된다고 하심', 0]\n",
            "['재시작 후에도 동일 증상 지속', 0]\n",
            "['타이어 펑크 육안 확인', 3]\n",
            "['내비 지속 전원 켜졌다 꺼짐으로 내비 후방카메라도 안 된다며 인입', 0]\n",
            "['차량이 흔들린다고 함', 2]\n",
            "['운행 중 타이어 공기압 경고등 점등되어 인입', 3]\n",
            "['내비게이션 전원 불가로 인입', 0]\n",
            "['내비게이션 안돼서 문의', 0]\n",
            "['블랙박스 메모리카드 없음', 1]\n",
            "['내비 지속 꺼짐으로 인입', 0]\n",
            "['사고 팀 확인', 0]\n",
            "['내비게이션 문제 발생으로 인입', 0]\n",
            "['타이어가 끝까지 돌리면 흔들림 차량 운전하기 무서움', 2]\n",
            "['내비게이션이 되지 않음으로 인입', 0]\n",
            "['차 케어 제보', 3]\n",
            "['내비 소리가 나오지 않음', 0]\n",
            "['와이파이 이용 불가로 인입', 0]\n",
            "['지우는 중이라고 하만하고 실행 안됨', 0]\n",
            "['반납 완료하고 유입', 0]\n",
            "['내비 또 안된다고 유입 준비 중입니다라고 만나오고 안된다고 함', 0]\n",
            "['내비 오작동 재진입', 0]\n",
            "['차량 운행 중 덜덜거리고 와이퍼 작동이 안 되어 인입 차량 변경 요구', 2]\n",
            "['차량 내비가 아예 켜지지가 않고 내부에 쓰레기가 많음', 0]\n",
            "['공기압 경고등 지속 점등 전우 타이어 점검 필요', 3]\n",
            "['타이어 터짐', 3]\n",
            "['이전에 월 일날 동일 차종 예약한 이전에도 내비게이션 안됨', 0]\n",
            "['카드 분실 필요', 4]\n",
            "['지우는 중 오후로 진행이 안 됨', 0]\n",
            "['기타 네비 반납 시간이 시로 되어있어 인입', 0]\n",
            "['운행 중 와이파이 연결 계속 끊김 내비게이션 사용 불가', 0]\n",
            "['내비게이션 sd카드 오류 나서 인입', 0]\n",
            "['내비게이션 이용불가', 0]\n",
            "['블랙박스 떨어짐 다시 붙여놓긴 했으나 접착력 약하다고 함', 1]\n",
            "['타이어 파손 육안 확인 운행 전', 3]\n",
            "['서비스가 지연되고 있음으로 인입', 0]\n",
            "['비접촉으로 운행 중 타이어 공기압 낮아짐으로 펑크', 3]\n",
            "['기타 타이어에 못이 박혀있다고 함', 3]\n",
            "['내비게이션 와이파이 접속이 끊겼다고 내비 작동 안 함 검색하다 초기화면으로 되돌아간다고 함 후방카메라 처음에 켜졌다고 깜깜하고 꺼지고 에러 뜬다고 함', 0]\n",
            "['현장 조치 불가하다고 함 임시로 메꾸어 단거리는 주행 가능하다고 함', 3]\n",
            "['타이어 공기압 점등되어 육안 확연히 오른쪽 타이어 뒷바퀴 펑크나 있다고 함', 3]\n",
            "['결제 내역 문의', 0]\n",
            "['화면이 껐다 켜짐 반복됨', 0]\n",
            "['긴급출동 기사 인입', 3]\n",
            "['타이어 육안으로 확인 시 펑크로 확인됨', 3]\n",
            "['어제는 내비게이션이 들어오다 나가다 했는데 오늘은 전원이 전혀 들어오지 않았음', 0]\n",
            "['블랙박스 메모리카드 부족하다고 확인된다며 인입', 1]\n",
            "['핸들러 인입 내비게이션 작동 불가 문의', 0]\n",
            "['최초 화면으로 전환 불가 상황', 0]\n",
            "['공기압 경고 등 점등', 3]\n",
            "['내비게이션 티맵 연결이 되지 않고 있어서 인입', 0]\n",
            "['내비게이션 연결 안 됨 및 사용 불가', 0]\n",
            "['내비게이션 안됨 인터넷 확인할 수 없다 함', 0]\n",
            "['네비 고장', 0]\n",
            "['블루투스 연결 시 내비게이션 화면이 미디어로 지속 넘어가서 주행 중에 내비게이션을 재조직해야 함', 0]\n",
            "['고객 반납했으나 내비 인터넷 연결 안 되었으나 그냥 이용 후 반납했다며 점검 요청', 0]\n",
            "['모닝 어반 쏘카를 이용했는데 내비게이션에 소리가 안 나오더라고요 음량을 최대로 했는데 원래 안 나오게 되어있는 건지', 0]\n",
            "['단말기를 연결하라는 문구 발생 확인 후 조치 필요', 0]\n",
            "['금일 이용 후 반납 내비게이션 안됨 로그아웃 되어 있다고 오류 발생하였으며 의자 밑 낙엽들이 나와서 좀 치우긴 했는데 덜 치워진 것 같아 문의', 0]\n",
            "['vip 공업사 입고 전우 타이어 교체 완료', 3]\n",
            "['내비 켜지지 않음', 0]\n",
            "['공기압 경고 등 점 등 사진 보내심', 3]\n",
            "['운행 전 전 좌 타이어 펑크 문의', 3]\n",
            "['내비가 안됨', 0]\n",
            "['TMAP 실행 중입니다 화면에서 작동되지 않음 TCS 재시작으로도 해당 문제 반복됨', 0]\n",
            "['네비게이현 T맵 실행 중 이후 화면 변화 없음', 0]\n",
            "['내비 작동 안 된다 하심', 0]\n",
            "['전조등 경고등 점등 및 네비 안 켜짐', 0]\n",
            "['블랙박스 메모리카드 확인 후 정상작동 완료 소닉붐', 1]\n",
            "['조수석 뒷바퀴에 못이 박혀있어서 때우긴 했는데', 3]\n",
            "['내비게이션 조작 방법 문의', 0]\n",
            "['내비가 안 된다며 인입', 0]\n",
            "['컨트롤 패드 인터넷 연결 불가로 인입', 0]\n",
            "['이전 이용 시 내비게이션 음성이 출력되지 않았다고 제보', 0]\n",
            "['내비게이션 전원을 키면 지도 화면 뜨고 거기서 화면이 멈춤 클릭도 안 됨', 0]\n",
            "['네비 재시작 이전에도 같은 차 이용했는데 계속 네비 문제 있다고 점검 안 하냐고 함 몇 번을 전화했는지 보라고 항의', 0]\n",
            "['차 운행하러 왔는데 타이어 바람이 아예 없는 걸로 확인되어 인입', 3]\n",
            "['고객님 내비게이션 고장 인입', 0]\n",
            "['내비 안 켜짐', 0]\n",
            "['이용차량 내비게이션 이상으로 이용 어려움 겪었다 함', 0]\n",
            "['네비 소리 안 남', 0]\n",
            "['소리 출력되지 않아 인입', 0]\n",
            "['클박 열화 현상', 1]\n",
            "['내비 연결 안 됨', 0]\n",
            "['내비게이션 및 usb 연결 불가 문의', 0]\n",
            "['네비게이션 차량 문제로 추후 대차하기로 했다고 함', 0]\n",
            "['고속도로 주행 중 타이어 퍼짐', 3]\n",
            "['내비게이션 정상 작동되지 않음', 0]\n",
            "['블랙박스 메모리카드 확인문구 뜸', 1]\n",
            "['네비 네트워크 오류', 0]\n",
            "['내비 고장으로 인입', 0]\n",
            "['블랙박스가 양면테이프가 떨어지고 운전석 쪽 유리창 옆 플라스틱이 튀어나와있음', 1]\n",
            "['블랙박스 메모리카드 분실되어 문의', 1]\n",
            "['내비 고장 GPS 신호도 약하다고 함', 0]\n",
            "['주차된 차량 뒤로 다른 차량이 막고 있어 출차 불가', 0]\n",
            "['내비게이션 GPS 접수 안됨', 0]\n",
            "['차량 내 와이파이가 잡히지 않음', 0]\n",
            "['내비게이션 컴플레인 해서 다시 켜주셨는데 또 오류', 0]\n",
            "['T맵 실행 준비 중 문구 지속 발생 tcs', 0]\n",
            "['내비 소리 출력 불량 지지직 거림', 0]\n",
            "['내비 검색하는 자판 안 눌린다 함', 0]\n",
            "['내비게이션 실행 준비 중으로 만 뜸 해결 방법 있는지', 0]\n",
            "['시동 후 작동 불가하나 tcs 재시작 후 정상작동 확인', 0]\n",
            "['내비게이션 이용 안 됨', 0]\n",
            "['시간 연장 필요 차량 엔진 떨림', 2]\n",
            "['타이어 펑크로 인해 장애 블록', 3]\n",
            "['내비 장애 인입', 0]\n",
            "['내비게이션 화면 들어오지 않음', 0]\n",
            "['긴급출동 가시 바꿔주신 다함', 3]\n",
            "['와이파이 연결되지 않아 티맵 이용불가하다고 나옴', 0]\n",
            "['후방카메라 안된다고 함 네트워트 연결도 잘 안된다며 인입', 0]\n",
            "['내비 오작동', 0]\n",
            "['차량 꿀렁거림이 있어 인 입', 2]\n",
            "['내비게이션 전원 불가', 0]\n",
            "['타이어 피스 박힘 펑크 수리 완료 완료 소닉붐', 3]\n",
            "['시동 시 내비게이션 작동 불가', 0]\n",
            "['고객님 내비게이션 불량 인입', 0]\n",
            "['블랙박스 탈거', 1]\n",
            "['오른쪽 앞 타이어 바람 꺼짐', 3]\n",
            "['내비게이션 정상작동하나 시간 연장 버튼이 눌리지 않음', 0]\n",
            "['하이패스가 카드가 삽입되어있지 않다는 멘트 들림 하이패스 구간 지나갈 때 경고음 들림', 4]\n",
            "['내비게이션이 안돼서 인입', 0]\n",
            "['내비게이션 안됨 워셔액도 없음', 0]\n",
            "['카오디오가 안 눌린다 함', 0]\n",
            "['와이파이 오작동', 0]\n",
            "['내비 업데이트 오류로 화면 안 나오고 후방 센서 감지 불가 현 예약 건은 운행 가능하나 내일 예약 건 운행 위험할 거 같다고 함', 0]\n",
            "['내비게이션 작동 불가', 0]\n",
            "['내비게이션이 되지 않음으로 인입', 0]\n",
            "['긴급출동 조치로 때웠으나 타이어 교체 필요하다 하심', 3]\n",
            "['내비게이션 전원은 들어오고 터치도 되는데 장소를 검색할 수 없어 인입', 0]\n",
            "['여러 번의 재부팅 시도에도 불구하고 티맵 준비 중이라는 문구만 나오며 실행되지 않음', 0]\n",
            "['내비게이션 오작동', 0]\n",
            "['블랙박스 탈 거문의', 1]\n",
            "['내비게이션이랑 후방카메라 안된다고 하심', 0]\n",
            "['내비 재시작 후에도 지속 작동 안 된다며 재진입', 0]\n",
            "['타이어 펑크 후 우', 3]\n",
            "['타이어 펑크로 인입', 3]\n",
            "['내비게이션이 꺼지지 않음', 0]\n",
            "['내비 업데이트 초기화 화면이 지속되고 초기화도 안되어 인입', 0]\n",
            "['내비게이션 되지 않음으로 인입', 0]\n",
            "['전원이 자꾸 꺼짐', 0]\n",
            "['워셔액 부족 주행 시 차량 떨림 발생', 2]\n",
            "['내비 네트워크 연결 안 돼서 불편하다 함', 0]\n",
            "['차량 시동 맘대로 꺼지며 심하게 떨린다고 하심', 2]\n",
            "['내비게이션 안되신다 문의', 0]\n",
            "['조수석 뒷바퀴', 3]\n",
            "['블랙박스 탈거돼서 인입', 1]\n",
            "['네비 화면 안 켜짐', 0]\n",
            "['내비게이션 화면 전환 안됨', 0]\n",
            "['차량 네트워크 연결이 안 된다고 나옴', 0]\n",
            "['블랙박스 오류로 인입', 1]\n",
            "['모본 접수', 1]\n",
            "['내비게이션 안되셔서 인입', 0]\n",
            "['정차 시 차량 진동소음 심하다고 하심', 2]\n",
            "['사진 보내 주심 차량은 전액 환불 요청', 3]\n",
            "['전원가능부', 0]\n",
            "['타이어 펑크나 있다며 인입', 3]\n",
            "['전우 타이어 펑크 난 부분으로 접촉 내용 없으시고 차량 다시 이용하시려는 상황에 발견하신 부분으로 인입', 3]\n",
            "['임시로 지렁이 끼웠으나 펑크 난 곳이 사이드라서 기사가 완벽하게 조치가 안 될 거 같다고 하셨다며 문의', 3]\n",
            "['내비게이션 인터넷 연결이 안 됨', 0]\n",
            "['오른쪽 앞 타이어가 펑크 난 거 같음 운행 시작 전 못 봤으나 하다 보니 이상한 소리가 나서 보니까 파손이 육안상으로 보임', 3]\n",
            "['내비게이션 안 켜짐 사진 첨부', 0]\n",
            "['타이어 파스', 3]\n",
            "['내비게이션이 안 켜져서 인입', 0]\n",
            "['내비 전원 들어오지 않음', 0]\n",
            "['차량 내비게이션 sd카드 오류뜸', 0]\n",
            "['브레이크가 살짝 밀리는 느낌 납니다', 2]\n",
            "['파인드라이브 내비 작동 불가로 인입', 0]\n",
            "['TCS 오작동 수시로 연결이 안 됨', 0]\n",
            "['내비게이션 소리가 안 난다고 하심', 0]\n",
            "['내비게이션이 안됨 자꾸 인터넷 연결 확인하라고 나온', 0]\n",
            "['내비 오작동 문의', 0]\n",
            "['전 좌 타이어 파스 인입', 3]\n",
            "['내비게이션 먹통', 0]\n",
            "['TCS 화면 터치 안됨', 0]\n",
            "['운행 시 차체 흔들림이 심함', 2]\n",
            "['차량 운행 중 내비게이션 자꾸 꺼지고 재부팅됨 해결 방법 없는지', 0]\n",
            "['내비게이션 안돼서 인입', 0]\n",
            "['내비게이션 서버 접속 지연이라고 하면서 정상 작동이 되지 않고 있음', 0]\n",
            "['고객님 내비게이션 불량인 입', 0]\n",
            "['접촉은 했는지 안 했다고 하심 운행 전 왼쪽 뒤 타이어가 펑크가 나있다', 3]\n",
            "['내비게이션 작동 안 됨 문의', 0]\n",
            "['워셔액도 안 나오고 차량이 심하게 꿀렁거림 또한 내비 작동 불가 차량 문제 있어서 바꾼 건데 또 문제 발생하였다며 불만 호소', 0]\n",
            "['내비게이션 실행 문제', 0]\n",
            "['내비 안된다고 유입 준비 중입니다라고 많 나오고 안된다고 함', 0]\n",
            "['디스플레이부분 전원 들어오지 않음', 0]\n",
            "['내비게이션 작동 안 됨 계속 지우는 중이라고만 뜸', 0]\n",
            "['내비가 아예 안 켜진다고 인입', 0]\n",
            "['내비게이션 오작동 문의', 0]\n",
            "['내비게이션 이용 불가 서비스가 지연되고 있다는 메시지에서 넘어가지 않음', 0]\n",
            "['네비 안됨', 0]\n",
            "['내비 작동 안 됨', 0]\n",
            "['내비게이션 이용 불가', 0]\n",
            "['내비 오작동으로 tcs 재 시작했으나 안되어 사진 발송 후인 입', 0]\n",
            "['타이어 파손 육안 확인', 3]\n",
            "['차량 확인 결과 가라앉아있음', 3]\n",
            "['내비가 떨어져 있어서 볼 수가 없다 하심', 0]\n",
            "['다름이 아니라 쏘카 빌릴 때마다 자주 이러더라 연결하면 갑자기 누가 사용 중인 네비라면서 뜨고 내비 또 재부팅하고 아니면 잘 가다가 연결 끊어지고 그전에는 좀 이해했는데 늦게 연결되는 건 어제는 연결 계속 안되고 길 가다가 누가 사용 중이라며 끊겨서 가는 길과 오는 길에 길 헤매고 어제는 진심 화가 났음 왜 이런 건지', 0]\n",
            "['TMAP 실행 준비 중입니다 잠시 후 TMAT이 실행됩니다 만 계속 뜨', 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfbF0jR6EIdM"
      },
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518,
          "referenced_widgets": [
            "fd4707c4d32b443d8964f5fa784e92d7",
            "5b438a5562b14a1da046097690656771",
            "ee8e008d6c8a400795e73ea6c879ed93",
            "8d05a6e29c7b47acafec08947dc0d56f",
            "e5709f041e8c4f47ba50b654cc6999f8",
            "c5ff603007f841f98c66f7ef09deea63",
            "9c3199d3e24541ea8b8ba7ebc9b585f2",
            "a6f8daefb8034ff88a4511c3d1924468"
          ]
        },
        "id": "B1IFlRQPo-GP",
        "outputId": "84e38f03-f9f0-4eac-e9b3-0f30c7d80dfb"
      },
      "source": [
        "\n",
        "# Setting parameters\n",
        "max_len = 164 # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n",
        "batch_size = 64\n",
        "warmup_ratio = 0.1\n",
        "num_epochs = 5\n",
        "max_grad_norm = 1\n",
        "log_interval = 200\n",
        "learning_rate = 5e-5\n",
        "\n",
        "data_train = BERTDataset(train_list, 0, 1, tok, max_len, True, False)\n",
        "data_test = BERTDataset(test_list, 0, 1, tok, max_len, True, False)\n",
        "\n",
        "# pytorch용 DataLoader 사용\n",
        "train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n",
        "test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n",
        "\n",
        "\n",
        "\n",
        "class BERTClassifier(nn.Module):\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 hidden_size = 768,\n",
        "                 num_classes = 5, # softmax 사용 <- binary일 경우는 2\n",
        "                 dr_rate=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__()\n",
        "        self.bert = bert\n",
        "        self.dr_rate = dr_rate\n",
        "                 \n",
        "        self.classifier = nn.Linear(hidden_size , num_classes)\n",
        "        if dr_rate:\n",
        "            self.dropout = nn.Dropout(p=dr_rate)\n",
        "    \n",
        "    def gen_attention_mask(self, token_ids, valid_length):\n",
        "        attention_mask = torch.zeros_like(token_ids)\n",
        "        for i, v in enumerate(valid_length):\n",
        "            attention_mask[i][:v] = 1\n",
        "        return attention_mask.float()\n",
        "\n",
        "    def forward(self, token_ids, valid_length, segment_ids):\n",
        "        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n",
        "        \n",
        "        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n",
        "        if self.dr_rate:\n",
        "            out = self.dropout(pooler)\n",
        "        return self.classifier(out)\n",
        "      \n",
        "model = BERTClassifier(bertmodel, dr_rate=0.5).to(device)\n",
        "\n",
        "# Prepare optimizer and schedule (linear warmup and decay)\n",
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "\n",
        "# 옵티마이저 선언\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n",
        "loss_fn = nn.CrossEntropyLoss() # softmax용 Loss Function 정하기 <- binary classification도 해당 loss function 사용 가능\n",
        "\n",
        "t_total = len(train_dataloader) * num_epochs\n",
        "warmup_step = int(t_total * warmup_ratio)\n",
        "\n",
        "scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n",
        "\n",
        "# 학습 평가 지표인 accuracy 계산 -> 얼마나 타겟값을 많이 맞추었는가\n",
        "def calc_accuracy(X,Y):\n",
        "    max_vals, max_indices = torch.max(X, 1)\n",
        "    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n",
        "    return train_acc\n",
        "  \n",
        "# 모델 학습 시작\n",
        "for e in range(num_epochs):\n",
        "    train_acc = 0.0\n",
        "    test_acc = 0.0\n",
        "    model.train()\n",
        "    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids = token_ids.long().to(device)\n",
        "        segment_ids = segment_ids.long().to(device)\n",
        "        valid_length= valid_length\n",
        "        label = label.long().to(device)\n",
        "        out = model(token_ids, valid_length, segment_ids)\n",
        "        loss = loss_fn(out, label)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm) # gradient clipping\n",
        "        optimizer.step()\n",
        "        scheduler.step()  # Update learning rate schedule\n",
        "        train_acc += calc_accuracy(out, label)\n",
        "        if batch_id % log_interval == 0:\n",
        "            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n",
        "    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n",
        "    \n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:78: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fd4707c4d32b443d8964f5fa784e92d7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=21.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c5e0ef173f7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mvalid_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-c5e0ef173f7d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, valid_length, segment_ids)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m         embedding_output = self.embeddings(\n\u001b[0;32m--> 753\u001b[0;31m             \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposition_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m         )\n\u001b[1;32m    755\u001b[0m         encoder_outputs = self.encoder(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0minputs_embeds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0mtoken_type_embeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoken_type_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_type_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    156\u001b[0m         return F.embedding(\n\u001b[1;32m    157\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 158\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1916\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 11.17 GiB total capacity; 10.62 GiB already allocated; 2.81 MiB free; 10.74 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658,
          "referenced_widgets": [
            "14fe2330494c4d09a3926c8b634d88d0",
            "eac392bff51147ab91ade2ad6957eb65",
            "2c49f4d7d37a442187a579f5cf31bcae",
            "deca24955d1242e7a49f6f963a43c99e",
            "05d46418461b4939919cfa385a54600a",
            "58c4eaf06c8b4f068e52b2c8caa4c631",
            "9b3456f7262c48c794401224417eb52c",
            "83eeb8b77b2842b7912dad5c37d24b17",
            "393a3e20435347eb8ccdda4b000b54f1",
            "53f252976f8b47e18087c6ac439ba674",
            "ada04ec8fa014074a04bb174063fed35",
            "d0515eb1f8584f4abcdd5cc3df0db27f",
            "197bb5160b1845b2a4d03ac38da17f0e",
            "416d30bdddec483185529ca1d849e8d5",
            "8290e52474d140049a27efde1569e66e",
            "405b0d23c5594fd4be7ce9a599e59527"
          ]
        },
        "id": "fqwk7B17bB02",
        "outputId": "7b040541-ac8e-4ad8-c3c8-cd652a733169"
      },
      "source": [
        "\n",
        "# 테스트 문장 예측\n",
        "test_sentence = '네비게이션 낮음'\n",
        "test_label = 0 # 실제 라벨\n",
        "\n",
        "unseen_test = pd.DataFrame([[test_sentence, test_label]], columns = [['질문 내용', '질병명']])\n",
        "unseen_values = unseen_test.values\n",
        "test_set = BERTDataset(unseen_values, 0, 1, tok, max_len, True, False)\n",
        "test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=5)\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_input)):\n",
        "  token_ids = token_ids.long().to(device)\n",
        "  segment_ids = segment_ids.long().to(device)\n",
        "  valid_length= valid_length\n",
        "  out = model(token_ids, valid_length, segment_ids)\n",
        "  print(out)\n",
        "    \n",
        "model.eval() # 평가 모드로 변경\n",
        "\n",
        "for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n",
        "    token_ids = token_ids.long().to(device)\n",
        "    segment_ids = segment_ids.long().to(device)\n",
        "    valid_length= valid_length\n",
        "    label = label.long().to(device)\n",
        "    out = model(token_ids, valid_length, segment_ids)\n",
        "    test_acc += calc_accuracy(out, label)\n",
        "print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  # This is added back by InteractiveShellApp.init_path()\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14fe2330494c4d09a3926c8b634d88d0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 1.8092, -0.4894, -0.9793,  0.6097, -0.6609]], device='cuda:0',\n",
            "       grad_fn=<AddmmBackward>)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "393a3e20435347eb8ccdda4b000b54f1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=6.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-873d4950b5a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mvalid_length\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtest_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcalc_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch {} test acc {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_id\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-15fc555cfebc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_ids, valid_length, segment_ids)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_attention_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_type_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msegment_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdr_rate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    760\u001b[0m             \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_extended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         )\n\u001b[1;32m    764\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states)\u001b[0m\n\u001b[1;32m    437\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 )\n\u001b[1;32m    441\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    369\u001b[0m     ):\n\u001b[1;32m    370\u001b[0m         self_attention_outputs = self.attention(\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m         )\n\u001b[1;32m    373\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself_attention_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    313\u001b[0m     ):\n\u001b[1;32m    314\u001b[0m         self_outputs = self.self(\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         )\n\u001b[1;32m    317\u001b[0m         \u001b[0mattention_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Take the dot product between \"query\" and \"key\" to get the raw attention scores.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m         \u001b[0mattention_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattention_scores\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mattention_mask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0;31m# Apply the attention mask is (precomputed for all layers in BertModel forward() function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 48.00 MiB (GPU 0; 11.17 GiB total capacity; 10.55 GiB already allocated; 14.81 MiB free; 10.73 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EdrQGLZbBsn"
      },
      "source": [
        "# 대표 증상 5개 추출\n",
        "data1 = dataset_train1[dataset_train1['type'] == '타이어_파스/펑크']\n",
        "data2 = dataset_train1[dataset_train1['type'] == '내비게이션_고장']\n",
        "data3 = dataset_train1[dataset_train1['type'] == '블랙박스_고장']\n",
        "data4 = dataset_train1[dataset_train1['type'] == '하이패스_분실']\n",
        "data5 = dataset_train1[dataset_train1['type'] == '주행_차량떨림']"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}